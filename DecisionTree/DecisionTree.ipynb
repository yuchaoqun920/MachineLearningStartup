{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ref: http://www.hankcs.com/ml/decision-tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import json\n",
    "import math\n",
    "# from math import log\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"\n",
    "    计算训练数据集中的Y随机变量的香农熵\n",
    "    :param dataSet:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    numEntries = len(dataSet)  # 实例的个数\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:  # 遍历每个实例，统计标签的频次\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys(): \n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "#     print json.dumps(labelCounts, encoding='UTF-8', ensure_ascii=False)\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key]) / numEntries\n",
    "        # shannonEnt -= prob * log(prob, 2)  # log base 2\n",
    "        shannonEnt -= prob * math.log(prob, 2)   # log base 2\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "青年 5\n",
      "[[\"否\", \"否\", \"一般\", \"拒绝\"], [\"否\", \"否\", \"好\", \"拒绝\"], [\"是\", \"否\", \"好\", \"同意\"], [\"是\", \"是\", \"一般\", \"同意\"], [\"否\", \"否\", \"一般\", \"拒绝\"]]\n"
     ]
    }
   ],
   "source": [
    "def createDataSet():\n",
    "    \"\"\"\n",
    "    创建数据集\n",
    " \n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataSet = [[u'青年', u'否', u'否', u'一般', u'拒绝'],\n",
    "               [u'青年', u'否', u'否', u'好', u'拒绝'],\n",
    "               [u'青年', u'是', u'否', u'好', u'同意'],\n",
    "               [u'青年', u'是', u'是', u'一般', u'同意'],\n",
    "               [u'青年', u'否', u'否', u'一般', u'拒绝'],\n",
    "               [u'中年', u'否', u'否', u'一般', u'拒绝'],\n",
    "               [u'中年', u'否', u'否', u'好', u'拒绝'],\n",
    "               [u'中年', u'是', u'是', u'好', u'同意'],\n",
    "               [u'中年', u'否', u'是', u'非常好', u'同意'],\n",
    "               [u'中年', u'否', u'是', u'非常好', u'同意'],\n",
    "               [u'老年', u'否', u'是', u'非常好', u'同意'],\n",
    "               [u'老年', u'否', u'是', u'好', u'同意'],\n",
    "               [u'老年', u'是', u'否', u'好', u'同意'],\n",
    "               [u'老年', u'是', u'否', u'非常好', u'同意'],\n",
    "               [u'老年', u'否', u'否', u'一般', u'拒绝'],\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有房子', u'信贷情况']\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return dataSet, labels\n",
    "\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    \"\"\"\n",
    "    按照给定特征划分数据集\n",
    "    :param dataSet: 待划分的数据集\n",
    "    :param axis: 划分数据集的特征的维度\n",
    "    :param value: 特征的值\n",
    "    :return: 符合该特征的所有实例（并且自动移除掉这维特征）\n",
    "    \"\"\"\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]  # 删掉这一维特征\n",
    "            reducedFeatVec.extend(featVec[axis + 1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "def calcConditionalEntropy(dataSet, i, featList, uniqueVals):\n",
    "    \"\"\"\n",
    "    计算X_i给定的条件下，Y的条件熵\n",
    "    :param dataSet:数据集\n",
    "    :param i:维度i\n",
    "    :param featList: 数据集特征列表\n",
    "    :param uniqueVals: 数据集特征集合\n",
    "    :return:条件熵\n",
    "    \"\"\"\n",
    "    ce = 0.0\n",
    "    for value in uniqueVals:\n",
    "        subDataSet = splitDataSet(dataSet, i, value)\n",
    "        prob = len(subDataSet) / float(len(dataSet))    # 极大似然估计概率(没准也可以用拉普拉斯估计/贝叶斯估计)\n",
    "        ce += prob * calcShannonEnt(subDataSet)  # ∑pH(Y|X=xi) 条件熵的计算\n",
    "    return ce\n",
    "    \n",
    "def calcInformationGain(dataSet, baseEntropy, i):\n",
    "    \"\"\"\n",
    "    计算信息增益\n",
    "    :param dataSet:数据集\n",
    "    :param baseEntropy:数据集中Y的信息熵\n",
    "    :param i: 特征维度i\n",
    "    :return: 特征i对数据集的信息增益g(dataSet|X_i)\n",
    "    \"\"\"\n",
    "    featList = [example[i] for example in dataSet]  # 第i维特征列表\n",
    "    uniqueVals = set(featList) # 转换成集合(去重)\n",
    "    # 计算每一个取值的条件熵\n",
    "    newEntropy = calcConditionalEntropy(dataSet, i, featList, uniqueVals)\n",
    "    infoGain = baseEntropy - newEntropy # 信息增益，就是熵的减少，也就是不确定性的减少\n",
    "    return infoGain\n",
    "\n",
    "def calcInformationGainRate(dataSet, baseEntropy, i):\n",
    "    \"\"\"\n",
    "    计算信息增益比(C4.5)\n",
    "    :param dataSet:数据集\n",
    "    :param baseEntropy:数据集中Y的信息熵\n",
    "    :param i: 特征维度i\n",
    "    :return: 特征i对数据集的信息增益g(dataSet|X_i)\n",
    "    \"\"\"\n",
    "    return calcInformationGain(dataSet, baseEntropy, i) / baseEntropy\n",
    "\n",
    "g_dataset,g_labels = createDataSet()\n",
    "# print g_dataset\n",
    "# print g_labels\n",
    "qingnian_dataset = splitDataSet(g_dataset, 0, u'青年')\n",
    "print u'青年', len(qingnian_dataset)\n",
    "print json.dumps(qingnian_dataset, encoding='UTF-8', ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"否\", \"否\", \"否\", \"是\", \"否\", \"否\", \"否\", \"是\", \"是\", \"是\", \"是\", \"是\", \"否\", \"否\", \"否\"]\n",
      "set([u'\\u662f', u'\\u5426'])\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "featList = [example[i] for example in g_dataset]\n",
    "uniqueVals = set(featList)\n",
    "print json.dumps(featList, encoding='UTF-8', ensure_ascii=False)\n",
    "print uniqueVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970950594455\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import json\n",
    "from math import log\n",
    "\n",
    "def calcShannonEntPrint(dataSet):\n",
    "    \"\"\"\n",
    "    计算训练数据集中的Y随机变量的香农熵\n",
    "    :param dataSet:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    numEntries = len(dataSet)  # 实例的个数\n",
    "    print numEntries\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:  # 遍历每个实例，统计标签的频次\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys(): \n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    print str(labelCounts).encode('utf8')\n",
    "    print json.dumps(labelCounts, encoding='UTF-8', ensure_ascii=False)\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key]) / numEntries\n",
    "        shannonEnt -= prob * log(prob, 2)   # log base 2\n",
    "    return shannonEnt\n",
    "\n",
    "print calcShannonEntPrint(g_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplitByID3(dataSet):\n",
    "    \"\"\"\n",
    "    选择最好的数据集划分方式\n",
    "    :param dataSet:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    numFeatures = len(dataSet[0]) - 1  # 最后一列是分类\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):  # 遍历所有维度特征\n",
    "        infoGain = calcInformationGain(dataSet, baseEntropy, i)\n",
    "        if(infoGain > bestInfoGain): # 选择最大的信息增益\n",
    "            bestInforGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature  # 返回最佳特征对应的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def majorityCnt(classList):\n",
    "    \"\"\"\n",
    "    返回出现次数最多的分类名称\n",
    "    :param classList: 类列表\n",
    "    :return: 出现次数最多的类名称\n",
    "    \"\"\"\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "def createTree(dataSet, labels, chooseBestFeatureToSplitFunc=chooseBestFeatureToSplitByID3):\n",
    "    \"\"\"\n",
    "    创建决策树\n",
    "    :param dataSet:数据集\n",
    "    :param labels:数据集每一维的名称\n",
    "    :return:决策树\n",
    "    \"\"\"\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0] # 当类别完全相同则停止继续划分\n",
    "    if len(dataSet[0]) == 1:  # 当只有一个特征的时候，遍历完所有实例返回出现次数最多的类别\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplitFunc(dataSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel: {}}\n",
    "    del (labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:] # 复制操作\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)\n",
    "        \n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# Filename: treePlotter.py\n",
    "# Author：hankcs\n",
    "# Date: 2015/2/9 21:24\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义文本框和箭头格式\n",
    "decisionNode = dict(boxstyle=\"round4\", color='#3366FF')  # 定义判断结点形态\n",
    "leafNode = dict(boxstyle=\"circle\", color='#FF6633')  # 定义叶结点形态\n",
    "arrow_args = dict(arrowstyle=\"<-\", color='g')  # 定义箭头\n",
    "\n",
    "\n",
    "# 绘制带箭头的注释\n",
    "def plotNode(nodeTxt, centerPt, parentPt, nodeType):\n",
    "    createPlot.ax1.annotate(nodeTxt, xy=parentPt, xycoords='axes fraction',\n",
    "                            xytext=centerPt, textcoords='axes fraction',\n",
    "                            va=\"center\", ha=\"center\", bbox=nodeType, arrowprops=arrow_args)\n",
    "\n",
    "\n",
    "# 计算叶结点数\n",
    "def getNumLeafs(myTree):\n",
    "    numLeafs = 0\n",
    "    firstStr = myTree.keys()[0]\n",
    "    secondDict = myTree[firstStr]\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__ == 'dict':\n",
    "            numLeafs += getNumLeafs(secondDict[key])\n",
    "        else:\n",
    "            numLeafs += 1\n",
    "    return numLeafs\n",
    "\n",
    "\n",
    "# 计算树的层数\n",
    "def getTreeDepth(myTree):\n",
    "    maxDepth = 0\n",
    "    firstStr = myTree.keys()[0]\n",
    "    secondDict = myTree[firstStr]\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__ == 'dict':\n",
    "            thisDepth = 1 + getTreeDepth(secondDict[key])\n",
    "        else:\n",
    "            thisDepth = 1\n",
    "        if thisDepth > maxDepth:\n",
    "            maxDepth = thisDepth\n",
    "    return maxDepth\n",
    "\n",
    "\n",
    "# 在父子结点间填充文本信息\n",
    "def plotMidText(cntrPt, parentPt, txtString):\n",
    "    xMid = (parentPt[0] - cntrPt[0]) / 2.0 + cntrPt[0]\n",
    "    yMid = (parentPt[1] - cntrPt[1]) / 2.0 + cntrPt[1]\n",
    "    createPlot.ax1.text(xMid, yMid, txtString, va=\"center\", ha=\"center\", rotation=30)\n",
    "\n",
    "\n",
    "def plotTree(myTree, parentPt, nodeTxt):\n",
    "    numLeafs = getNumLeafs(myTree)\n",
    "    depth = getTreeDepth(myTree)\n",
    "    firstStr = myTree.keys()[0]\n",
    "    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs)) / 2.0 / plotTree.totalW, plotTree.yOff)\n",
    "    plotMidText(cntrPt, parentPt, nodeTxt)  # 在父子结点间填充文本信息\n",
    "    plotNode(firstStr, cntrPt, parentPt, decisionNode)  # 绘制带箭头的注释\n",
    "    secondDict = myTree[firstStr]\n",
    "    plotTree.yOff = plotTree.yOff - 1.0 / plotTree.totalD\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__ == 'dict':\n",
    "            plotTree(secondDict[key], cntrPt, str(key))\n",
    "        else:\n",
    "            plotTree.xOff = plotTree.xOff + 1.0 / plotTree.totalW\n",
    "            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)\n",
    "            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key))\n",
    "    plotTree.yOff = plotTree.yOff + 1.0 / plotTree.totalD\n",
    "\n",
    "\n",
    "def createPlot(inTree):\n",
    "    fig = plt.figure(1, facecolor='white')\n",
    "    fig.clf()\n",
    "    axprops = dict(xticks=[], yticks=[])\n",
    "    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops)\n",
    "    plotTree.totalW = float(getNumLeafs(inTree))\n",
    "    plotTree.totalD = float(getTreeDepth(inTree))\n",
    "    plotTree.xOff = -0.5 / plotTree.totalW;\n",
    "    plotTree.yOff = 1.0;\n",
    "    plotTree(inTree, (0.5, 1.0), '')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# Filename: testTree.py\n",
    "# Author：hankcs\n",
    "# Date: 2014-04-19 下午9:19\n",
    " \n",
    "###########中文支持################\n",
    "import sys\n",
    "# from tree import *\n",
    " \n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "from pylab import *\n",
    " \n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']  # 指定默认字体\n",
    "mpl.rcParams['axes.unicode_minus'] = False  # 解决保存图像时负号'-'显示为方块的问题\n",
    "##################################\n",
    "\n",
    "# create test tree\n",
    "myDat, labels = createDataSet()\n",
    "myTree = createTree(myDat, labels)\n",
    "# 绘制决策树\n",
    "# import treePlotter\n",
    "createPlot(myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplitByC45(dataSet):\n",
    "    \"\"\"\n",
    "    选择最好的数据集划分方式\n",
    "    :param dataSet:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    numFeatures = len(dataSet[0]) - 1  # 最后一列是分类\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGainRate = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):  # 遍历所有维度特征\n",
    "        infoGainRate = calcInformationGainRate(dataSet, baseEntropy, i)\n",
    "        if(infoGainRate > bestInfoGainRate): # 选择最大的信息增益\n",
    "            bestInfoGainRate = infoGainRate\n",
    "            bestFeature = i\n",
    "    print 'bestFeature:', bestFeature\n",
    "    return bestFeature # 返回最佳特征对应的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myDat, labels = createDataSet()\n",
    "myTree = createTree(myDat, labels, chooseBestFeatureToSplitByC45)\n",
    "createPlot(myTree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
